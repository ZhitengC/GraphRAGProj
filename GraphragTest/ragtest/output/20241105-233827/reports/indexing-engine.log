23:38:27,524 graphrag.config.read_dotenv INFO Loading pipeline .env file
23:38:27,527 graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "glm-4",
        "max_tokens": 2000,
        "temperature": 0.95,
        "top_p": 0.7,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "http://localhost:3000/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./",
    "reporting": {
        "type": "file",
        "base_dir": "inputs/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "inputs/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "embedding-2",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:3000/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 1,
        "batch_max_tokens": 8000,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "glm-4",
            "max_tokens": 2000,
            "temperature": 0.95,
            "top_p": 0.7,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:3000/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "glm-4",
            "max_tokens": 2000,
            "temperature": 0.95,
            "top_p": 0.7,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:3000/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "glm-4",
            "max_tokens": 2000,
            "temperature": 0.95,
            "top_p": 0.7,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:3000/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "glm-4",
            "max_tokens": 2000,
            "temperature": 0.95,
            "top_p": 0.7,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:3000/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": true,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
23:38:27,527 graphrag.index.create_pipeline_config INFO skipping workflows 
23:38:27,529 graphrag.index.run INFO Running pipeline
23:38:27,529 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at inputs/artifacts
23:38:27,529 graphrag.index.input.load_input INFO loading input from root_dir=input
23:38:27,529 graphrag.index.input.load_input INFO using file storage for input
23:38:27,530 graphrag.index.storage.file_pipeline_storage INFO search input for files matching .*\.txt$
23:38:27,530 graphrag.index.input.text INFO found text files from input, found [('currentPrompt.txt', {})]
23:38:27,531 graphrag.index.input.text INFO Found 1 files, loading 1
23:38:27,533 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_final_covariates', 'create_summarized_entities', 'join_text_units_to_covariate_ids', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
23:38:27,533 graphrag.index.run INFO Final # of rows loaded: 1
23:38:27,625 graphrag.index.run INFO Running workflow: create_base_text_units...
23:38:27,625 graphrag.index.run INFO dependencies for create_base_text_units: []
23:38:27,627 datashaper.workflow.workflow INFO executing verb orderby
23:38:27,628 datashaper.workflow.workflow INFO executing verb zip
23:38:27,630 datashaper.workflow.workflow INFO executing verb aggregate_override
23:38:27,632 datashaper.workflow.workflow INFO executing verb chunk
23:38:27,720 datashaper.workflow.workflow INFO executing verb select
23:38:27,722 datashaper.workflow.workflow INFO executing verb unroll
23:38:27,724 datashaper.workflow.workflow INFO executing verb rename
23:38:27,726 datashaper.workflow.workflow INFO executing verb genid
23:38:27,728 datashaper.workflow.workflow INFO executing verb unzip
23:38:27,731 datashaper.workflow.workflow INFO executing verb copy
23:38:27,732 datashaper.workflow.workflow INFO executing verb filter
23:38:27,737 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
23:38:27,831 graphrag.index.run INFO Running workflow: create_base_extracted_entities...
23:38:27,831 graphrag.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units']
23:38:27,831 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
23:38:27,839 datashaper.workflow.workflow INFO executing verb entity_extract
23:38:27,841 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=http://localhost:3000/v1
23:38:27,845 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for glm-4: TPM=0, RPM=0
23:38:27,845 graphrag.index.llm.load_llm INFO create concurrency limiter for glm-4: 25
23:38:27,865 datashaper.workflow.workflow INFO executing verb merge_graphs
23:38:27,874 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
23:38:27,967 graphrag.index.run INFO Running workflow: create_final_covariates...
23:38:27,967 graphrag.index.run INFO dependencies for create_final_covariates: ['create_base_text_units']
23:38:27,967 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
23:38:27,975 datashaper.workflow.workflow INFO executing verb extract_covariates
23:38:27,989 datashaper.workflow.workflow INFO executing verb window
23:38:27,992 datashaper.workflow.workflow INFO executing verb genid
23:38:27,995 datashaper.workflow.workflow INFO executing verb convert
23:38:28,2 datashaper.workflow.workflow INFO executing verb rename
23:38:28,5 datashaper.workflow.workflow INFO executing verb select
23:38:28,6 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_covariates.parquet
23:38:28,109 graphrag.index.run INFO Running workflow: create_summarized_entities...
23:38:28,109 graphrag.index.run INFO dependencies for create_summarized_entities: ['create_base_extracted_entities']
23:38:28,109 graphrag.index.run INFO read table from storage: create_base_extracted_entities.parquet
23:38:28,119 datashaper.workflow.workflow INFO executing verb summarize_descriptions
23:38:30,958 httpx INFO HTTP Request: POST http://localhost:3000/v1/chat/completions "HTTP/1.1 200 OK"
23:38:30,960 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.8179999999993015. input_tokens=171, output_tokens=59
23:38:32,595 httpx INFO HTTP Request: POST http://localhost:3000/v1/chat/completions "HTTP/1.1 200 OK"
23:38:32,596 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.450000000004366. input_tokens=167, output_tokens=64
23:38:32,606 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_summarized_entities.parquet
23:38:32,698 graphrag.index.run INFO Running workflow: join_text_units_to_covariate_ids...
23:38:32,698 graphrag.index.run INFO dependencies for join_text_units_to_covariate_ids: ['create_final_covariates']
23:38:32,699 graphrag.index.run INFO read table from storage: create_final_covariates.parquet
23:38:32,710 datashaper.workflow.workflow INFO executing verb select
23:38:32,714 datashaper.workflow.workflow INFO executing verb aggregate_override
23:38:32,716 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_covariate_ids.parquet
23:38:32,810 graphrag.index.run INFO Running workflow: create_base_entity_graph...
23:38:32,810 graphrag.index.run INFO dependencies for create_base_entity_graph: ['create_summarized_entities']
23:38:32,810 graphrag.index.run INFO read table from storage: create_summarized_entities.parquet
23:38:32,821 datashaper.workflow.workflow INFO executing verb cluster_graph
23:38:32,852 datashaper.workflow.workflow INFO executing verb select
23:38:32,853 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_entity_graph.parquet
23:38:32,950 graphrag.index.run INFO Running workflow: create_final_entities...
23:38:32,950 graphrag.index.run INFO dependencies for create_final_entities: ['create_base_entity_graph']
23:38:32,950 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
23:38:32,962 datashaper.workflow.workflow INFO executing verb unpack_graph
23:38:32,975 datashaper.workflow.workflow INFO executing verb rename
23:38:32,980 datashaper.workflow.workflow INFO executing verb select
23:38:32,985 datashaper.workflow.workflow INFO executing verb dedupe
23:38:32,990 datashaper.workflow.workflow INFO executing verb rename
23:38:32,995 datashaper.workflow.workflow INFO executing verb filter
23:38:33,6 datashaper.workflow.workflow INFO executing verb text_split
23:38:33,12 datashaper.workflow.workflow INFO executing verb drop
23:38:33,18 datashaper.workflow.workflow INFO executing verb merge
23:38:33,39 datashaper.workflow.workflow INFO executing verb text_embed
23:38:33,40 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=http://localhost:3000/v1
23:38:33,43 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for embedding-2: TPM=0, RPM=0
23:38:33,44 graphrag.index.llm.load_llm INFO create concurrency limiter for embedding-2: 25
23:38:33,49 graphrag.index.verbs.text.embed.strategies.openai INFO embedding 225 inputs via 225 snippets using 225 batches. max_batch_size=1, max_tokens=8000
23:38:33,598 httpx INFO HTTP Request: POST http://localhost:3000/v1/embeddings "HTTP/1.1 200 OK"
23:38:33,600 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.5469999999986612. input_tokens=63, output_tokens=0
23:38:34,541 httpx INFO HTTP Request: POST http://localhost:3000/v1/embeddings "HTTP/1.1 200 OK"
23:38:34,541 httpx INFO HTTP Request: POST http://localhost:3000/v1/embeddings "HTTP/1.1 200 OK"
23:38:34,543 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.4910000000018044. input_tokens=50, output_tokens=0
23:38:34,545 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.4910000000018044. input_tokens=48, output_tokens=0
23:38:34,853 httpx INFO HTTP Request: POST http://localhost:3000/v1/embeddings "HTTP/1.1 200 OK"
23:38:34,853 httpx INFO HTTP Request: POST http://localhost:3000/v1/embeddings "HTTP/1.1 200 OK"
23:38:34,856 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.8009999999994761. input_tokens=43, output_tokens=0
23:38:34,858 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.8029999999998836. input_tokens=47, output_tokens=0
23:38:34,870 datashaper.workflow.workflow INFO executing verb drop
23:38:34,876 datashaper.workflow.workflow INFO executing verb filter
23:38:34,885 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_entities.parquet
23:38:35,10 graphrag.index.run INFO Running workflow: create_final_nodes...
23:38:35,10 graphrag.index.run INFO dependencies for create_final_nodes: ['create_base_entity_graph']
23:38:35,10 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
23:38:35,25 datashaper.workflow.workflow INFO executing verb layout_graph
23:38:35,63 datashaper.workflow.workflow INFO executing verb unpack_graph
23:38:35,79 datashaper.workflow.workflow INFO executing verb unpack_graph
23:38:35,95 datashaper.workflow.workflow INFO executing verb drop
23:38:35,102 datashaper.workflow.workflow INFO executing verb filter
23:38:35,117 datashaper.workflow.workflow INFO executing verb select
23:38:35,124 datashaper.workflow.workflow INFO executing verb rename
23:38:35,130 datashaper.workflow.workflow INFO executing verb join
23:38:35,140 datashaper.workflow.workflow INFO executing verb convert
23:38:35,161 datashaper.workflow.workflow INFO executing verb rename
23:38:35,162 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_nodes.parquet
23:38:35,275 graphrag.index.run INFO Running workflow: create_final_communities...
23:38:35,275 graphrag.index.run INFO dependencies for create_final_communities: ['create_base_entity_graph']
23:38:35,275 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
23:38:35,292 datashaper.workflow.workflow INFO executing verb unpack_graph
23:38:35,310 datashaper.workflow.workflow INFO executing verb unpack_graph
23:38:35,327 datashaper.workflow.workflow INFO executing verb aggregate_override
23:38:35,336 datashaper.workflow.workflow INFO executing verb join
23:38:35,346 datashaper.workflow.workflow INFO executing verb join
23:38:35,357 datashaper.workflow.workflow INFO executing verb concat
23:38:35,365 datashaper.workflow.workflow INFO executing verb filter
23:38:35,394 datashaper.workflow.workflow INFO executing verb aggregate_override
23:38:35,404 datashaper.workflow.workflow INFO executing verb join
23:38:35,415 datashaper.workflow.workflow INFO executing verb filter
23:38:35,433 datashaper.workflow.workflow INFO executing verb fill
23:38:35,442 datashaper.workflow.workflow INFO executing verb merge
23:38:35,453 datashaper.workflow.workflow INFO executing verb copy
23:38:35,461 datashaper.workflow.workflow INFO executing verb select
23:38:35,463 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_communities.parquet
23:38:35,579 graphrag.index.run INFO Running workflow: join_text_units_to_entity_ids...
23:38:35,584 graphrag.index.run INFO dependencies for join_text_units_to_entity_ids: ['create_final_entities']
23:38:35,588 graphrag.index.run INFO read table from storage: create_final_entities.parquet
23:38:35,613 datashaper.workflow.workflow INFO executing verb select
23:38:35,622 datashaper.workflow.workflow INFO executing verb unroll
23:38:35,632 datashaper.workflow.workflow INFO executing verb aggregate_override
23:38:35,634 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_entity_ids.parquet
23:38:35,740 graphrag.index.run INFO Running workflow: create_final_relationships...
23:38:35,740 graphrag.index.run INFO dependencies for create_final_relationships: ['create_final_nodes', 'create_base_entity_graph']
23:38:35,740 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
23:38:35,744 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
23:38:35,764 datashaper.workflow.workflow INFO executing verb unpack_graph
23:38:35,782 datashaper.workflow.workflow INFO executing verb filter
23:38:35,804 datashaper.workflow.workflow INFO executing verb rename
23:38:35,813 datashaper.workflow.workflow INFO executing verb filter
23:38:35,835 datashaper.workflow.workflow INFO executing verb drop
23:38:35,846 datashaper.workflow.workflow INFO executing verb compute_edge_combined_degree
23:38:35,858 datashaper.workflow.workflow INFO executing verb convert
23:38:35,878 datashaper.workflow.workflow INFO executing verb convert
23:38:35,879 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_relationships.parquet
23:38:35,990 graphrag.index.run INFO Running workflow: join_text_units_to_relationship_ids...
23:38:35,991 graphrag.index.run INFO dependencies for join_text_units_to_relationship_ids: ['create_final_relationships']
23:38:35,991 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
23:38:36,14 datashaper.workflow.workflow INFO executing verb select
23:38:36,24 datashaper.workflow.workflow INFO executing verb unroll
23:38:36,36 datashaper.workflow.workflow INFO executing verb aggregate_override
23:38:36,47 datashaper.workflow.workflow INFO executing verb select
23:38:36,49 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_relationship_ids.parquet
23:38:36,158 graphrag.index.run INFO Running workflow: create_final_community_reports...
23:38:36,158 graphrag.index.run INFO dependencies for create_final_community_reports: ['create_final_relationships', 'create_final_nodes', 'create_final_covariates']
23:38:36,158 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
23:38:36,161 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
23:38:36,163 graphrag.index.run INFO read table from storage: create_final_covariates.parquet
23:38:36,187 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
23:38:36,200 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
23:38:36,212 datashaper.workflow.workflow INFO executing verb prepare_community_reports_claims
23:38:36,224 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
23:38:36,238 datashaper.workflow.workflow INFO executing verb prepare_community_reports
23:38:36,239 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=1 => 225
23:38:36,296 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 225
23:38:36,353 datashaper.workflow.workflow INFO executing verb create_community_reports
23:39:03,739 httpx INFO HTTP Request: POST http://localhost:3000/v1/chat/completions "HTTP/1.1 200 OK"
23:39:03,740 graphrag.llm.openai.utils INFO Warning: Error decoding faulty json, attempting repair
23:39:03,740 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 27.37999999999738. input_tokens=2277, output_tokens=547
23:39:07,619 httpx INFO HTTP Request: POST http://localhost:3000/v1/chat/completions "HTTP/1.1 200 OK"
23:39:07,619 graphrag.llm.openai.utils INFO Warning: Error decoding faulty json, attempting repair
23:39:07,620 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 31.25800000000163. input_tokens=2260, output_tokens=619
23:39:11,97 httpx INFO HTTP Request: POST http://localhost:3000/v1/chat/completions "HTTP/1.1 200 OK"
23:39:11,98 graphrag.llm.openai.utils INFO Warning: Error decoding faulty json, attempting repair
23:39:11,98 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 34.73399999999674. input_tokens=2193, output_tokens=559
23:39:48,796 httpx INFO HTTP Request: POST http://localhost:3000/v1/chat/completions "HTTP/1.1 200 OK"
23:39:48,796 graphrag.llm.openai.utils INFO Warning: Error decoding faulty json, attempting repair
23:39:48,797 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 72.42900000000373. input_tokens=7516, output_tokens=1228
23:40:30,570 httpx INFO HTTP Request: POST http://localhost:3000/v1/chat/completions "HTTP/1.1 200 OK"
23:40:30,570 graphrag.llm.openai.utils INFO Warning: Error decoding faulty json, attempting repair
23:40:30,571 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 41.75600000000122. input_tokens=8688, output_tokens=673
23:40:30,595 datashaper.workflow.workflow INFO executing verb window
23:40:30,596 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
23:40:30,733 graphrag.index.run INFO Running workflow: create_final_text_units...
23:40:30,733 graphrag.index.run INFO dependencies for create_final_text_units: ['join_text_units_to_entity_ids', 'join_text_units_to_covariate_ids', 'join_text_units_to_relationship_ids', 'create_base_text_units']
23:40:30,733 graphrag.index.run INFO read table from storage: join_text_units_to_entity_ids.parquet
23:40:30,736 graphrag.index.run INFO read table from storage: join_text_units_to_covariate_ids.parquet
23:40:30,738 graphrag.index.run INFO read table from storage: join_text_units_to_relationship_ids.parquet
23:40:30,740 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
23:40:30,765 datashaper.workflow.workflow INFO executing verb select
23:40:30,777 datashaper.workflow.workflow INFO executing verb rename
23:40:30,789 datashaper.workflow.workflow INFO executing verb join
23:40:30,803 datashaper.workflow.workflow INFO executing verb join
23:40:30,818 datashaper.workflow.workflow INFO executing verb join
23:40:30,832 datashaper.workflow.workflow INFO executing verb aggregate_override
23:40:30,846 datashaper.workflow.workflow INFO executing verb select
23:40:30,847 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
23:40:30,972 graphrag.index.run INFO Running workflow: create_base_documents...
23:40:30,972 graphrag.index.run INFO dependencies for create_base_documents: ['create_final_text_units']
23:40:30,979 graphrag.index.run INFO read table from storage: create_final_text_units.parquet
23:40:31,7 datashaper.workflow.workflow INFO executing verb unroll
23:40:31,21 datashaper.workflow.workflow INFO executing verb select
23:40:31,33 datashaper.workflow.workflow INFO executing verb rename
23:40:31,47 datashaper.workflow.workflow INFO executing verb join
23:40:31,62 datashaper.workflow.workflow INFO executing verb aggregate_override
23:40:31,76 datashaper.workflow.workflow INFO executing verb join
23:40:31,92 datashaper.workflow.workflow INFO executing verb rename
23:40:31,105 datashaper.workflow.workflow INFO executing verb convert
23:40:31,120 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_documents.parquet
23:40:31,235 graphrag.index.run INFO Running workflow: create_final_documents...
23:40:31,235 graphrag.index.run INFO dependencies for create_final_documents: ['create_base_documents']
23:40:31,235 graphrag.index.run INFO read table from storage: create_base_documents.parquet
23:40:31,264 datashaper.workflow.workflow INFO executing verb rename
23:40:31,266 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_documents.parquet
